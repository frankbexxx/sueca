# ü§ñ Plano de Integra√ß√£o e Melhorias da IA - Pr√≥xima Sess√£o

**Data:** Pr√≥xima sess√£o de desenvolvimento  
**Objetivo:** Integrar IA externa em produ√ß√£o, melhorar heur√≠sticas e explorar machine learning

---

## üìã Estado Atual

### ‚úÖ O que j√° existe:
- **Servi√ßo FastAPI** (`sueca-ai/`) com endpoint `/play`
- **Heur√≠stica b√°sica** implementada (`engine/heuristics.py`)
- **Cliente frontend** (`frontend/src/services/aiClient.ts`)
- **Integra√ß√£o parcial** no `GameBoard.tsx` (fallback para IA local)
- **Testes b√°sicos** (`tests/test_heuristics_cases.py`)

### üîç Funcionalidades atuais da heur√≠stica:
- Seguir naipe quando poss√≠vel
- Tentar ganhar com carta mais baixa poss√≠vel
- Evitar gastar 7 se √Ås do naipe n√£o saiu
- Cortar com trunfo baixo quando necess√°rio
- Descartar cartas baixas quando n√£o pode ganhar

---

## üéØ Tarefas para Pr√≥xima Sess√£o

### 1. Deploy e Integra√ß√£o em Produ√ß√£o ‚≠ê‚≠ê‚≠ê (Prioridade Alta)

#### 1.1 Deploy do Servi√ßo Python
- [ ] Escolher plataforma (Render/Fly.io/Railway/Cloud Run)
- [ ] Configurar vari√°veis de ambiente
- [ ] Fazer deploy do servi√ßo FastAPI
- [ ] Testar endpoint `/health` e `/play` em produ√ß√£o
- [ ] Configurar CORS para origem do Vercel (produ√ß√£o)

#### 1.2 Configura√ß√£o no Frontend
- [ ] Adicionar `REACT_APP_AI_SERVICE_URL` no Vercel (vari√°vel de ambiente)
- [ ] Testar integra√ß√£o com servi√ßo em produ√ß√£o
- [ ] Implementar toggle "Usar IA externa" nas Configura√ß√µes (opcional)
- [ ] Adicionar indicador visual quando IA externa est√° ativa
- [ ] Implementar timeout e retry logic no cliente

#### 1.3 Valida√ß√£o e Testes
- [ ] Testar jogo completo com IA externa
- [ ] Verificar fallback para IA local se servi√ßo indispon√≠vel
- [ ] Testar em diferentes cen√°rios (in√≠cio, meio, fim de jogo)

---

### 2. Melhorias de Heur√≠stica ‚≠ê‚≠ê (Prioridade M√©dia)

#### 2.1 Prote√ß√µes Adicionais
- [ ] **Evitar gastar K/Q se √Ås n√£o saiu** (quando n√£o ganha garantidamente)
  - Implementar tracking de cartas altas por naipe
  - S√≥ jogar K/Q se √Ås j√° saiu ou se ganha o trick
  
- [ ] **Melhor escolha de descarte**
  - Priorizar descartar cartas mais fracas primeiro
  - Evitar descartar cartas que podem ser √∫teis mais tarde
  - Considerar valor das cartas (pontos) ao descartar

#### 2.2 Estrat√©gia de Vazas
- [ ] **Micro-simula√ß√µes de vazas**
  - Avaliar valor da vaza vs custo da carta
  - Decidir se vale a pena gastar carta alta para ganhar
  - Considerar cartas restantes na m√£o

- [ ] **Conserva√ß√£o de trunfo**
  - Guardar trunfo alto para vazas importantes
  - Usar trunfo baixo para cortar quando necess√°rio
  - Evitar gastar todo o trunfo cedo

#### 2.3 Tracking de Cartas
- [ ] **Melhor tracking de cartas jogadas**
  - Manter hist√≥rico completo de todas as cartas jogadas
  - Calcular probabilidades de cartas restantes
  - Usar informa√ß√£o para decis√µes melhores

#### 2.4 Seguir Naipe Inteligente
- [ ] **Sempre seguir naipe quando poss√≠vel** (regra b√°sica)
- [ ] **Escolher melhor carta do naipe**
  - Se pode ganhar: jogar carta mais baixa que ganha
  - Se n√£o pode ganhar: jogar carta mais baixa (descartar)
  - Considerar se parceiro pode ganhar

---

### 3. Machine Learning e Aprendizado ‚≠ê (Prioridade Baixa - Explorat√≥rio)

#### 3.1 Coleta de Dados
- [ ] **Sistema de logging de jogadas**
  - Logar todas as decis√µes da IA (carta escolhida, raz√£o, contexto)
  - Logar resultado do trick (quem ganhou, pontos)
  - Logar resultado final do jogo (quem ganhou, pontua√ß√£o)

- [ ] **Estrutura de dados para ML**
  - Definir features relevantes (m√£o, trick, hist√≥rico, trunfo)
  - Criar dataset estruturado
  - Armazenar em formato adequado (JSON, CSV, ou banco de dados)

#### 3.2 Modelo de Aprendizado (Futuro)
- [ ] **An√°lise de padr√µes**
  - Identificar jogadas que resultam em vit√≥rias
  - Analisar erros comuns da heur√≠stica atual
  - Criar m√©tricas de performance

- [ ] **Modelo de refor√ßo (Reinforcement Learning)**
  - Definir recompensas (ganhar trick = +1, perder = -1, ganhar jogo = +10)
  - Treinar modelo com hist√≥rico de jogos
  - Comparar performance vs heur√≠stica

- [ ] **Modelo supervisionado (Supervised Learning)**
  - Treinar com jogos de jogadores experientes
  - Aprender padr√µes de jogadas vencedoras
  - Validar com testes

#### 3.3 Integra√ß√£o de ML (Futuro)
- [ ] **API para modelo treinado**
  - Endpoint `/play-ml` que usa modelo treinado
  - Fallback para heur√≠stica se modelo n√£o dispon√≠vel
  - Compara√ß√£o A/B entre heur√≠stica e ML

---

### 4. Melhorias T√©cnicas ‚≠ê‚≠ê

#### 4.1 Performance
- [ ] **Cache de decis√µes**
  - Cache de jogadas legais
  - Cache de c√°lculos de heur√≠stica
  - Reduzir tempo de resposta

- [ ] **Otimiza√ß√£o de c√≥digo**
  - Profiling do c√≥digo Python
  - Otimizar fun√ß√µes mais lentas
  - Melhorar estrutura de dados

#### 4.2 Debugging e Observabilidade
- [ ] **Logging estruturado**
  - Logs detalhados de decis√µes
  - M√©tricas de performance
  - Erros e exce√ß√µes

- [ ] **Endpoint de debug**
  - `/play-debug` que retorna raz√£o detalhada
  - Mostrar todas as op√ß√µes consideradas
  - Explicar decis√£o final

#### 4.3 Testes
- [ ] **Expandir testes unit√°rios**
  - Mais casos de teste para heur√≠stica
  - Testes de edge cases
  - Testes de integra√ß√£o

- [ ] **Testes de performance**
  - Medir tempo de resposta
  - Testar com diferentes tamanhos de estado
  - Validar escalabilidade

---

## üìä Estrutura de Dados para ML (Futuro)

### Features para Modelo:
```python
{
  "hand": ["AS", "KD", "5C", ...],  # 10 cartas
  "trick": ["2S", "3S"],             # Cartas no trick atual
  "trump": "S",                      # Naipe trunfo
  "played": ["AS", "KD", ...],       # Cartas j√° jogadas
  "history": [[...], [...]],         # Tricks anteriores
  "round_score": {"team1": 45, "team2": 30},  # Pontua√ß√£o atual
  "trick_number": 3,                 # N√∫mero do trick (1-10)
  "position": "lead" | "follow",     # Posi√ß√£o no trick
  "team": 1 | 2,                     # Equipa do jogador
}
```

### Labels (Supervised Learning):
```python
{
  "best_play": "AS",                 # Carta ideal (de jogador experiente)
  "trick_won": True,                 # Se ganhou o trick
  "round_won": True,                 # Se ganhou a ronda
  "game_won": True                   # Se ganhou o jogo
}
```

---

## üîÑ Fluxo de Trabalho Sugerido

### Fase 1: Deploy e Integra√ß√£o (2-3 horas)
1. Deploy do servi√ßo Python
2. Configura√ß√£o no Vercel
3. Testes b√°sicos de integra√ß√£o
4. Valida√ß√£o em produ√ß√£o

### Fase 2: Melhorias de Heur√≠stica (3-4 horas)
1. Implementar prote√ß√µes adicionais
2. Melhorar estrat√©gia de vazas
3. Expandir tracking de cartas
4. Testes e valida√ß√£o

### Fase 3: Prepara√ß√£o para ML (1-2 horas)
1. Sistema de logging
2. Estrutura de dados
3. Coleta inicial de dados
4. An√°lise preliminar

---

## üìù Notas Importantes

### Decis√µes T√©cnicas:
- **Plataforma de Deploy:** Avaliar custo vs performance (Render tem tier gratuito)
- **Formato de Dados:** JSON para simplicidade inicial
- **ML Framework:** Come√ßar com scikit-learn, evoluir para TensorFlow/PyTorch se necess√°rio

### Prioridades:
1. **Primeiro:** Deploy e integra√ß√£o funcionando
2. **Segundo:** Melhorias de heur√≠stica (impacto imediato)
3. **Terceiro:** Prepara√ß√£o para ML (investimento futuro)

### M√©tricas de Sucesso:
- IA externa funcionando em produ√ß√£o
- Heur√≠stica melhorada (mais vit√≥rias, menos erros)
- Sistema de logging ativo
- Base de dados de jogadas iniciada

---

## üöÄ Pr√≥ximos Passos Imediatos

1. **Come√ßar com deploy** - escolher plataforma e fazer deploy
2. **Testar integra√ß√£o** - validar que tudo funciona
3. **Melhorar heur√≠stica** - implementar prote√ß√µes mais inteligentes
4. **Preparar logging** - sistema b√°sico para coletar dados

---

**√öltima atualiza√ß√£o:** Dezembro 2025

